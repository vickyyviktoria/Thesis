df <- read.csv("rusukr.csv")
original <- read.csv("rusukr.csv")
names(df)
install.packages("writexl")
install.packages("car")
library(car)
library(writexl)
library(dplyr)
library(rtweet)
library(ggplot2)
library(tidytext)   ###NLP -> emotional lexicon
library(tidyr)
library(stringr)
library(psych)
library(lm.beta)
library(Hmisc)
library(corrplot)
library(epiDisplay)
library(quanteda)
library(textdata)
library(vader)
library(stargazer)
library(janitor)
library(summarytools)
library(oii)
library(psychTools)
library(DescTools)
library(MESS)
library(gmodels)
library(modeest)

install.packages("DescTools")
install.packages("MESS")


df$created_at[1]

min(df$datetime)
max(df$datetime)
###tweets from 2022-12-07 to 2022-12-20

as.POSIXct(df$created_at[1])
str(as.POSIXct(df$created_at[1]))

df <- df %>%
  mutate(datetime = as.POSIXct(created_at),
         row_num = row_number(),
         raw_text = tweet)
####three new variables addad
 

ts_plot(df)               ## graph
ts_plot(df, by="hours", col="violetred", lwd=1) +
  theme_classic() +
  labs(title = "Tweets about Russia-Ukraine war",
       x = "time in hours",
       y = "Number of Tweets")
#####adds a graph

colors()

df <- df %>%
  mutate(clean_tweet = tweet,
         clean_tweet = gsub("<U\\+?[0-9a-fA-F]+>", " ", clean_tweet),
         clean_tweet = tolower(clean_tweet),
         clean_tweet = gsub("@\\S+", "", clean_tweet),
         clean_tweet = gsub("http(s?):\\S+", "", clean_tweet),
         clean_tweet = gsub("#\\S+", "", clean_tweet),
         clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet),
         clean_tweet = gsub("[[:punct:]]", "", clean_tweet), 
         clean_tweet = gsub("[^\x20-\x7E]", "", clean_tweet),
         clean_tweet = gsub("[[:digit:]]", "", clean_tweet),
         clean_tweet = gsub("\n", " ", clean_tweet),
         clean_tweet = gsub("^\\s+|\\s+$|\\s+(?=\\s)", "", clean_tweet, perl=T))


#####new dataframe
df_words <- df %>%
  select(row_num, clean_tweet) %>%
  unnest_tokens(clean_tweet, output=word) %>%
  filter(!word %in% stop_words$word) %>%
  group_by(row_num) %>%
  summarise(cleaner_tweet= paste(word, collapse=" "))



 
df <- df %>%
  left_join(df_words)


keywords <- df %>%
  dplyr::select(row_num, clean_tweet) %>%
  unnest_tokens(clean_tweet, output=word) %>%
  filter(!word %in% stop_words$word) %>%
  count(word)%>%
  arrange(-n)

####graph 

df %>%
  dplyr::select(row_num, clean_tweet) %>%
  unnest_tokens(clean_tweet, output=word) %>%
  filter(!word %in% stop_words$word) %>%
  count(word) %>%
  top_n(25) %>%
  ggplot(aes(x= reorder(word, n), y= n)) +
  geom_bar(stat ="identity", fill= "violetred1")+
  coord_flip()+
  theme_minimal()+
  labs(x = "Most-Used Keywords", y = "Number of Tweets",
       title = "Keywords", x = "Words",
       y = "Frequency")




####### arranges the most important hashtags

hashtags <- df %>%
  dplyr::select(tweet) %>%
  mutate(hashtags=str_extract_all(tweet, "#\\S+"))%>%
  unnest(hashtags)%>%
  count(hashtags) %>%
  arrange(-n)

df$tweet

# creating/exporting into excel:

write_xlsx(hashtags,"hashtags.xlsx")
write_xlsx(keywords,"keywords.xlsx")



##############TUTORIAL 3

######sentiment analasys --> Bing, AFIN, NRC
get_sentiments("bing")
get_sentiments("afinn")
get_sentiments("nrc")

nrc <- get_sentiments("nrc")

nrc %>%
  count(sentiment) %>%
  arrange(-n)

df_nrc <- df %>%
  group_by(row_num) %>%
  unnest_tokens(cleaner_tweet, output=word)%>%
  full_join(get_sentiments("nrc")) %>%
  count(sentiment)%>%
  spread(sentiment, n, fill=0)

df <- df %>%
  left_join(df_nrc)



dflong <- df[c("row_num", "sadness", "anger", "fear", "disgust",
                          "surprise", "anticipation", "joy", "trust")] %>% 
  dplyr::group_by(row_num) %>%
  pivot_longer(cols = c("sadness", "anger", "fear", "disgust",
                        "surprise", "anticipation", "joy", "trust"),
               names_to = "emotion",
               values_to = "value"
  )



ggplot(dflong, aes(x=row_num,y=value,fill=emotion)) + 
  geom_bar(stat="identity", show.legend = FALSE) +
  facet_wrap(~emotion, ncol = 2, scales = "free_x") +
  theme_minimal() +
  labs(x = "", y = "")


####dictionary

sanctions = c("energy", "sanction*", "oil", "inflation", 
              "consequence*", "export*", "regulation*",
              "inter alias", "asset freeze", "credit bank of moscow",
              "dalnevostochny bank", "sberbank", "vnesheconombank",
              "vtb bank", "otkritie fc bank", "novikombank", "bank rossiya",
              "promsvyazbank", "internet research agency",
              "gas industry insurance company sogaz", "rosneft aero",
              "rosoboronexport", "npo high precision systems", 
              "kurganmashzavod", "russian helicopters", "united aircraft corporation",
              "united shipbuilding corporation", "reseatch and production corporation uralvagonzavod",
              "interdependent insurance group")

EU = c("eu", "europe*", "belarus*", "germany*", "poland*", "france*", "union", "austria*",
       "belgium*", "bulgaria*", "croatia*", "cyprus*", "czech republic*", "denmark*", "estounia*",
       "finland*", "greece*", "hungary*", "ireland*", "italy*", "latvia*", "lithuania*",
       "luxembourg*", "malta*", "netherlands*", "poland*", "portugal*", "romania*",
       "slovakia*", "slovenia*", "spain*", "sweden*")

economy = c("economy*", "economic*", "revenue*", "fund*", "banking*", "import*",
            "export*", "financial resource*", "financial state*", "savings",
            "hyperinflation", "stagflation", "monetary polic*", "currenc*",
            "reflation", "money", "consumer price index", "price*", "central bank",
            "interest rate*", "volatility", "unemployment", "recession", "gpd",
            "index*", "eurozone", "monetarism", "disinflation", "aggregate demand*",
            "investment*", "hoarding", "recession", "value*", "market*", "consumer*",
            "supplier*", "jobless*")


eusaneco.lexicon <- dictionary(list(sanctions = c("energy", "sanction*", "oil", "inflation", 
                                                     "consequence*", "export*", "regulation*",
                                                     "inter alias", "asset freeze", "credit bank of moscow",
                                                     "dalnevostochny bank", "sberbank", "vnesheconombank",
                                                     "vtb bank", "otkritie fc bank", "novikombank", "bank rossiya",
                                                     "promsvyazbank", "internet research agency",
                                                     "gas industry insurance company sogaz", "rosneft aero",
                                                     "rosoboronexport", "npo high precision systems", 
                                                     "kurganmashzavod", "russian helicopters", "united aircraft corporation",
                                                     "united shipbuilding corporation", "reseatch and production corporation uralvagonzavod",
                                                     "interdependent insurance group"),
                                       eu = c("eu", "europe*", "belarus*", "germany*", "poland*", "france*", "union", "austria*",
                                              "belgium*", "bulgaria*", "croatia*", "cyprus*", "czech republic*", "denmark*", "estounia*",
                                              "finland*", "greece*", "hungary*", "ireland*", "italy*", "latvia*", "lithuania*",
                                              "luxembourg*", "malta*", "netherlands*", "poland*", "portugal*", "romania*",
                                              "slovakia*", "slovenia*", "spain*", "sweden*"),
                                       economy = c("economy*", "economic*", "revenue*", "fund*", "banking*", "import*",
                                                   "export*", "financial resource*", "financial state*", "savings",
                                                   "hyperinflation", "stagflation", "monetary polic*", "currenc*",
                                                   "reflation", "money", "consumer price index", "price*", "central bank",
                                                   "interest rate*", "volatility", "unemployment", "recession", "gpd",
                                                   "index*", "eurozone", "monetarism", "disinflation", "aggregate demand*",
                                                   "investment*", "hoarding", "recession", "value*", "market*", "consumer*",
                                                   "supplier*", "jobless*")))
                                       

### document feature matrix
df_dfm <- dfm(df$cleaner_tweet, dictionary = eusaneco.lexicon)

df_dfm <- convert(df_dfm, "data.frame")

df_dfm <- df_dfm %>%
  mutate(row_num = row_number())

df <- df %>% left_join(df_dfm)


###grapth
tab1(df$sanctions)
tab1(df$economy)
tab1(df$fear)

pairs.panels(df[c("fear", "Total", "sanctions", "economy")], 
             method = "pearson", 
             hist.col = "purple",
             ellipses = T
)


#######level of measurement -> ratio

rcorr(as.matrix(df[c("eu", "sanctions", "economy", "sadness", "anger", "fear", "disgust", "trust", "joy", "anticipation")])
)

as.matrix(df[c("eu", "sanctions", "economy", "sadness", "anger", "fear", "disgust", "trust", "joy", "anticipation")])

df[c("eu", "sanctions", "economy", "sadness", "anger", "fear", "disgust", "trust", "joy", "anticipation")]


write.csv(df, "df_30_january_with_rcorr.csv")
save.image("env_30jan.Rdata")


###creating the user engagement subset

user_engagement <- df %>%
  group_by(row_num) %>%
  dplyr::select(like_count, retweet_count, quote_count) %>%
  cbind(Total = rowSums(user_engagement[2:4]))

df <- df %>%
  left_join(user_engagement)


df$economy_dummy <- ifelse(df$economy>0, 1, 0)
df$sanctions_dummy <- ifelse(df$sanctions>0, 1, 0)
df$fear_dummy <- ifelse(df$fear>0, 1, 0)
df$Total_dummy <- ifelse(df$Total>0, 1, 0)





####################Analasys

###fear

mean(df$fear)
##average of 1.39 fearful words

modeest::mfv(df$fear)

psych::describe(df$fear)

oii.freq(df$fear)
100-22.96

##22.96% of words have no fearful words, 77.04% have at least one,
##39.17% have exactly 1 fearful word, 22% have two, 10.16% have 3, 3.79% have 4, 1.35% have 5

barplot(table(df$fear))
boxplot(df$fear)
hist(df$fear)

###likes

mean(df$like_count)
##average likes are 11.91

psych::describe(df$like_count)
##range 78356, min 0, max 78356, sd 259.12

boxplot(df$like_count)
hist(df$like_count)

mfv(df$like_count)

###retweets

psych::describe(df$retweet_count)
##mean 2.61, range 13408, min 0, max 13408, sd 53.83, 

mfv(df$retweet_count)
##mode 0

boxplot(df$retweet_count)
hist(df$retweet_count)

###quotes

psych::describe(df$quote_count)

mfv(df$quote_count)

###total

psych::describe(df$Total)
###sd x 3 = 936.57
###14.7-936.57
312.19*3


mfv(df$Total)




var(df$fear)
var(df$sadness)
###sanctions

table(df$sanctions)

oii.freq(df$sanctions)
100-94.53

mean(df$sanctions)

barplot(table(df$sanctions))
boxplot(df$sanctions)
hist(df$sanctions)

###EU

oii.freq(df$eu)
100-90.96

mean(df$eu)

barplot(table(df$eu))
boxplot(df$fear)
hist(df$fear)

###economy

oii.freq(df$economy)

mean(df$economy)




######bivariate

###total and fear
## scatterplot

plot(df$fear, df$Total)
abline(lm(fear~Total, data=df))

### fear and sanctions
## t.test 

t.test(df$sanctions, df$fear_dummy)
##shows the significance

### cor.test
cor.test(df$fear, df$sanctions)
###cor = if strong or not, if plus or minus
##H0 - the more often fear is mentioned in a Tweet, the more often sanctions are mentioned

### fear and economy
## t.test 
t.test(df$fear_dummy, df$economy)

### cor.test
cor.test(df$fear, df$economy)


#### sanctions & economy
##crosstable
CrossTable(df$economy_dummy, df$sanctions_dummy, expected=TRUE)


### total and sanctions
## t.test 
t.test(df$Total_dummy, df$sanctions)

### cor.test
cor.test(df$Total, df$sanctions)


### total and economy
## t.test 
t.test(df$Total_dummy, df$economy)

### cor.test
cor.test(df$Total, df$economy)


##### multivariate linear model

###just a sidenote, because it's important to switch the order of the variables
##cor.test(IND, DEP)
##t.test(IND, DEP)
##lm(DEP~IND1+IND2+IND3+IND4)


lm2 <- lm(Total~fear+sanctions+economy, data=df)

summary(lm2)
#### regression function formula
##y=a+b*x
##dep=constant(intercept)+slope*IND
##fear=0.24+0.59*Danger+0.79*Legal

#dep=dependant variable; constant=the intercept nr; slope=the estimate; IND=independant variable

####### regression function lm2
###11.84+2.13*0.01+3.18*0.003-2.99*(-0.004)
### 11.88

11.84+2.13*0.01+3.18*0.003-2.99*(-0.004)

summary(lm.beta(lm2))
####to compare the estimate (if it is strong or not) even tho they previously were on different scales

avPlots(lm2)



